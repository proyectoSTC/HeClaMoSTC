# ğŸ¥ HeClaMoSTC - Herramienta de ClasificaciÃ³n de Movimientos para STC

**Sistema de DetecciÃ³n AutomÃ¡tica de Movimientos de Riesgo para SÃ­ndrome del TÃºnel Carpiano**

Desarrollado por: **Karen Nicolle Arango Valencia**  
Universidad: **Pontificia Universidad Javeriana - Cali**

---

## ğŸ“‹ DescripciÃ³n

HeClaMoSTC es un sistema completo de clasificaciÃ³n binaria que detecta automÃ¡ticamente movimientos de riesgo asociados al SÃ­ndrome del TÃºnel Carpiano (STC) a partir de seÃ±ales electromiogrÃ¡ficas (EMG).

### CaracterÃ­sticas principales:
- âœ… **ClasificaciÃ³n binaria**: RIESGO vs SEGURO
- âœ… **MÃºltiples modelos**: Machine Learning (ML) y Deep Learning (DL)
- âœ… **Sistema Dual**: CombinaciÃ³n de dos modelos especializados en cascada
- âœ… **Interfaz web intuitiva**: FÃ¡cil de usar, sin necesidad de cÃ³digo
- âœ… **Pipeline completo**: Filtrado â†’ NormalizaciÃ³n â†’ ClasificaciÃ³n â†’ VisualizaciÃ³n

---

## ğŸ¯ Movimientos Clasificados

**Movimientos de RIESGO (4):**
- Movimiento 13: FlexiÃ³n de muÃ±eca
- Movimiento 14: ExtensiÃ³n de muÃ±eca  
- Movimiento 15: DesviaciÃ³n radial
- Movimiento 16: DesviaciÃ³n ulnar

**Movimientos SEGUROS (13):**
- Movimientos 1-12: Agarres y gestos bÃ¡sicos
- Movimiento 17: Reposo

---

## ğŸ“¦ Estructura del Proyecto

```
HeClaMoSTC/
â”‚
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ index.html          # Interfaz web
â”‚   â””â”€â”€ app.js             # LÃ³gica del frontend
â”‚
â”œâ”€â”€ server.py              # Backend Flask API
â”œâ”€â”€ models/                # Modelos entrenados
â”‚   â”œâ”€â”€ *.pkl             # Modelos ML
â”‚   â”œâ”€â”€ *.keras           # Modelos DL
â”‚   â”œâ”€â”€ scaler.pkl        # Normalizador Z-score
â”‚   â””â”€â”€ metadata.json     # ConfiguraciÃ³n y mÃ©tricas
â”‚
â”œâ”€â”€ signals/              # SeÃ±ales de prueba
â”‚   â””â”€â”€ *.mat            # Archivos MATLAB con EMG
â”‚
â”œâ”€â”€ notebooks/            # Jupyter Notebooks
â”‚   â”œâ”€â”€ Copy_of_HeClaMoSTC_optimized.ipynb  # Entrenamiento
â”‚   â””â”€â”€ EMG_Spectral_Analysis.ipynb         # AnÃ¡lisis espectral
â”‚
â”œâ”€â”€ requirements.txt      # Dependencias Python
â””â”€â”€ README.md            # Este archivo
```

---

## ğŸš€ InstalaciÃ³n y ConfiguraciÃ³n

### Requisitos Previos

- **Python**: 3.8 o superior
- **pip**: Gestor de paquetes de Python
- **Google Colab**: Para entrenar modelos (opcional)

### 1. Clonar el Repositorio

```bash
git clone https://github.com/tu-usuario/HeClaMoSTC.git
cd HeClaMoSTC
```

### 2. Crear Entorno Virtual (Recomendado)

**Windows:**
```bash
python -m venv venv
venv\Scripts\activate
```

**Linux/Mac:**
```bash
python3 -m venv venv
source venv/bin/activate
```

### 3. Instalar Dependencias

```bash
pip install -r requirements.txt
```

### 4. Configurar Rutas

Edita `server.py` lÃ­nea 53 para ajustar la ruta de seÃ±ales externas:

```python
EXTERNAL_SIGNALS_DIR = Path(r'TU_RUTA_AQUI')  # Opcional
```

### 5. Crear Carpetas Necesarias

```bash
mkdir models signals frontend
```

### 6. Copiar Archivos

- Copia `index.html` y `app.js` a la carpeta `frontend/`
- Copia los modelos entrenados (`.pkl`, `.keras`) a la carpeta `models/`
- Copia `scaler.pkl` y `metadata.json` a la carpeta `models/`

---

## ğŸ® Uso de la AplicaciÃ³n Web

### Iniciar el Servidor

```bash
python server.py
```

DeberÃ­as ver:
```
======================================================================
SERVIDOR CLASIFICADOR STC
======================================================================

 Rutas: C:\...\models
 Window: 500ms, Overlap: 25.0%

 Sistema Dual DISPONIBLE:
   SAFE: RandomForest (precision 0.XXX)
   RISK: Ensemble_KNN (recall 0.XXX)

 http://localhost:5000
======================================================================
```

### Acceder a la AplicaciÃ³n

Abre tu navegador web y visita:
```
http://localhost:5000
```

### Flujo de ClasificaciÃ³n

#### **OpciÃ³n 1: Modo Independiente**

1. **Seleccionar Modo**: Elige "Modelo Independiente"
2. **Tipo de Modelo**: Selecciona ML o DL
3. **Modelo EspecÃ­fico**: 
   - **ML**: `ensemble_knn` o `random_forest`
   - **DL**: `cnn_lstm_attention` o `bilstm_attention`
4. **Seleccionar SeÃ±ales**: Marca las seÃ±ales `.mat` que deseas clasificar
5. **Clasificar**: Haz clic en "ğŸš€ CLASIFICAR SEÃ‘ALES"

#### **OpciÃ³n 2: Sistema Dual (Recomendado)**

1. **Seleccionar Modo**: Elige "Sistema Dual"
2. **Seleccionar SeÃ±ales**: Marca las seÃ±ales a clasificar
3. **Clasificar**: Haz clic en "ğŸš€ CLASIFICAR SEÃ‘ALES"

El sistema dual usa dos modelos especializados:
- **Especialista SAFE**: Alta precisiÃ³n en detectar movimientos seguros
- **Especialista RISK**: Alta sensibilidad en detectar movimientos de riesgo

### Cargar SeÃ±ales Propias

1. Haz clic en "Cargar .mat desde tu PC"
2. Selecciona uno o mÃ¡s archivos `.mat`
3. Haz clic en "ğŸ“¥ Subir seleccionados"
4. Las seÃ±ales aparecerÃ¡n en la lista automÃ¡ticamente

### Formato de Archivos .mat

Los archivos `.mat` deben contener:
- **Variable principal**: `emg` (matriz de seÃ±ales EMG)
- **Dimensiones**: `[n_muestras Ã— 12_canales]`
- **Frecuencia**: 2000 Hz
- **Metadata opcional**:
  - `subject`: NÃºmero de sujeto
  - `stimulus` o `restimulus`: NÃºmero de movimiento
  - `repetition` o `rerepetition`: NÃºmero de repeticiÃ³n

---

## ğŸ§  Entrenamiento de Modelos (Google Colab)

### Acceso al Notebook

El notebook de entrenamiento estÃ¡ diseÃ±ado para **Google Colab** con GPU.

**Link del Notebook**: `Copy_of_HeClaMoSTC_optimized.ipynb`

### ConfiguraciÃ³n del Entrenamiento

#### 1. Montar Google Drive

```python
from google.colab import drive
drive.mount('/content/drive')
```

#### 2. Configurar Rutas

Edita las rutas en la **SecciÃ³n 2**:

```python
class Config:
    BASE_DIR = Path('/content/drive/MyDrive')
    DATA_DIR = BASE_DIR / 'DB2_E1_only'  # Tu carpeta con datos
    SAVE_DIR = BASE_DIR / 'New_ML_DL_models_stc_optimized'
```

#### 3. Seleccionar Sujetos

**SecciÃ³n 3**:

```python
USE_ALL_SUBJECTS = True  # Para usar todos los sujetos
# O especificar:
SELECTED_SUBJECTS = [1, 2, 3, 4, 5]  # Lista personalizada
```

#### 4. Seleccionar Modelos

```python
SELECTED_MODELS = ['1', '2', '3', '4']  # Todos
# '1': Ensemble KNN
# '2': Random Forest
# '3': CNN+LSTM+Attention
# '4': BiLSTM+Attention
```

#### 5. TÃ©cnicas de Balanceo

**Para ML**:
```python
ML_BALANCE_TECHNIQUE = 'adasyn'  # 'none', 'adasyn', 'smote'
```

**Para DL**:
```python
DL_BALANCE_TECHNIQUE = 'augment_only'  
# 'none', 'augment_only', 'focal_loss', 'focal_loss+augment'
```

### Pipeline de Entrenamiento

El notebook ejecuta automÃ¡ticamente:

1. **Carga de datos**: Lee seÃ±ales EMG de archivos `.mat`
2. **Filtrado**: Butterworth (20-450 Hz) + Notch (50 Hz)
3. **SeparaciÃ³n**: Train (rep 1,3,4,6) / Val (rep 2) / Test (rep 5)
4. **NormalizaciÃ³n**: Z-score por canal
5. **SegmentaciÃ³n**: Ventanas de 500ms con 25% overlap
6. **ExtracciÃ³n de features** (ML):
   - Temporales: RMS, MAV, VAR, WL, SSC, ZC
   - Frecuenciales: MNF, MDF, PKF
   - Wavelet: EnergÃ­a de coeficientes
7. **Entrenamiento**: 
   - ML con balanceo ADASYN/SMOTE
   - DL con Data Augmentation y/o Focal Loss
8. **OptimizaciÃ³n**: Threshold optimization para maximizar F1-Score
9. **EvaluaciÃ³n**: MÃ©tricas en test set
10. **Guardado**: Modelos `.pkl` (ML) y `.keras` (DL)

### Resultados Generados

Al finalizar, encontrarÃ¡s en tu Google Drive:

```
New_ML_DL_models_stc_optimized/
â”œâ”€â”€ run_YYYYMMDD_HHMMSS/
â”‚   â”œâ”€â”€ artifacts/
â”‚   â”‚   â”œâ”€â”€ ensemble_knn.pkl
â”‚   â”‚   â”œâ”€â”€ random_forest.pkl
â”‚   â”‚   â”œâ”€â”€ cnn_lstm_attention.keras
â”‚   â”‚   â”œâ”€â”€ bilstm_attention.keras
â”‚   â”‚   â”œâ”€â”€ scaler.pkl
â”‚   â”‚   â””â”€â”€ metadata.json
â”‚   â”‚
â”‚   â””â”€â”€ plots/
â”‚       â”œâ”€â”€ metrics_comparison.png
â”‚       â”œâ”€â”€ confusion_matrices.png
â”‚       â”œâ”€â”€ roc_curves.png
â”‚       â””â”€â”€ training_history.png
```

### Descargar Modelos

1. Navega a `artifacts/` en Google Drive
2. Descarga todos los archivos:
   - `*.pkl` y `*.keras` (modelos)
   - `scaler.pkl` (normalizador)
   - `metadata.json` (configuraciÃ³n)
3. Copia los archivos a la carpeta `models/` de tu proyecto local

---

## ğŸ“Š Modelos Disponibles

### Machine Learning (ML)

#### 1. Ensemble Subspace KNN
- **Tipo**: Bagging de 30 clasificadores KNN
- **CaracterÃ­sticas**: 
  - K-vecinos: 7
  - MÃ©trica: Distancia euclidiana
  - Subsampling: 70% datos, 80% features
- **Ventaja**: Robusto a ruido, alta precisiÃ³n

#### 2. Random Forest
- **Tipo**: Ensemble de 200 Ã¡rboles de decisiÃ³n
- **CaracterÃ­sticas**:
  - Max depth: 30
  - Min samples split: 5
  - Max features: sqrt
- **Ventaja**: RÃ¡pido, interpretable

### Deep Learning (DL)

#### 3. CNN+LSTM+Attention
- **Arquitectura**:
  - 3 capas convolucionales (extracciÃ³n espacial)
  - BiLSTM (patrones temporales)
  - Mecanismo de atenciÃ³n (enfoque selectivo)
- **ParÃ¡metros**: ~500K
- **Ventaja**: Captura patrones espacio-temporales complejos

#### 4. BiLSTM+Attention
- **Arquitectura**:
  - 3 capas BiLSTM profundas
  - AtenciÃ³n multiplicativa
  - RegularizaciÃ³n L2 + Dropout 35%
- **ParÃ¡metros**: ~400K
- **Ventaja**: Excelente para secuencias largas

### Sistema Dual

Combina dos modelos ML en cascada:
- **Filtro SAFE**: Modelo con mayor precisiÃ³n (descarta falsos positivos)
- **Detector RISK**: Modelo con mayor recall (captura todos los riesgos)

**DecisiÃ³n**:
1. Si ambos coinciden â†’ Alta confianza
2. Si difieren â†’ Confianza media, prevalece detector RISK (conservador)

---

## ğŸ”§ ConfiguraciÃ³n TÃ©cnica

### ParÃ¡metros de Procesamiento

```python
FS = 2000                # Frecuencia de muestreo (Hz)
WINDOW_SIZE_MS = 500     # TamaÃ±o de ventana (ms)
OVERLAP = 0.25           # Solapamiento (25%)
N_CHANNELS = 12          # Canales EMG

# Filtrado
LOWCUT = 20              # Frecuencia baja (Hz)
HIGHCUT = 450            # Frecuencia alta (Hz)
NOTCH_FREQ = 50          # Filtro notch (Hz)
```

### HiperparÃ¡metros DL

```python
BATCH_SIZE = 64
EPOCHS = 100
LEARNING_RATE = 0.0005
DROPOUT = 0.35
L2_REG = 0.001
```

---

## ğŸ“Š AnÃ¡lisis Espectral de SeÃ±ales (Opcional)

### Notebook de VisualizaciÃ³n

Se incluye el notebook **`EMG_Spectral_Analysis.ipynb`** para anÃ¡lisis avanzado de seÃ±ales EMG.

#### Â¿Para quÃ© sirve?

Esta herramienta te permite:
- ğŸ“ˆ **Visualizar espectros de frecuencia** de seÃ±ales EMG sin filtrar
- ğŸ” **Comparar movimientos RISK vs SAFE** en el dominio espectral
- ğŸ“Š **Analizar consistencia** entre repeticiones del mismo movimiento
- ğŸ¯ **Identificar bandas de frecuencia dominantes** por canal
- ğŸ§ª **Validar calidad** de seÃ±ales antes de entrenar modelos

#### Â¿CÃ³mo usarlo?

1. Abre el notebook en **Google Colab**
2. Monta tu Google Drive con los datos
3. Ajusta la ruta en la configuraciÃ³n:
   ```python
   DATA_DIR = BASE_DIR / 'DB2_E1_only' / 'train'
   ```
4. Ejecuta todas las celdas secuencialmente
5. Revisa las grÃ¡ficas generadas:
   - Espectros de potencia por canal
   - ComparaciÃ³n temporal de seÃ±ales
   - AnÃ¡lisis de bandas de frecuencia
   - Mapas de calor de energÃ­a espectral

#### CaracterÃ­sticas

- **SeÃ±ales RAW**: Analiza seÃ±ales sin filtrado previo
- **12 canales EMG**: VisualizaciÃ³n individual y comparativa
- **40 sujetos**: AnÃ¡lisis poblacional completo
- **17 movimientos**: Clasificados en RISK (13-16) y SAFE (1-12, 17)
- **Bandas de frecuencia**: Very Low (0-20 Hz), Low (20-100 Hz), Mid (100-200 Hz), High (200-400 Hz), Very High (400-500 Hz)

#### Salidas tÃ­picas

- GrÃ¡ficas de espectro de potencia
- AnÃ¡lisis de correlaciÃ³n entre repeticiones
- ComparaciÃ³n espectral RISK vs SAFE
- DistribuciÃ³n de energÃ­a por banda de frecuencia
- EstadÃ­sticas descriptivas por movimiento

**Nota**: Este notebook es complementario y no es necesario para el funcionamiento de la aplicaciÃ³n principal. Ãšsalo para exploraciÃ³n y anÃ¡lisis de datos.

## ğŸ“ˆ InterpretaciÃ³n de Resultados

### Tarjetas de Resultados

Cada seÃ±al clasificada muestra:

- **Estado**: RIESGO (rojo, animado) o SEGURO (verde)
- **Confianza**: Alta o Media (solo en Sistema Dual)
- **Probabilidades**: % de SAFE vs RISK
- **Ventanas**: Total analizadas
- **Metadata**: Sujeto, movimiento, repeticiÃ³n
- **GrÃ¡fica**: SeÃ±al EMG del primer canal

### MÃ©tricas de EvaluaciÃ³n

- **Accuracy**: PrecisiÃ³n general
- **Precision**: De todos los RISK predichos, cuÃ¡ntos son realmente RISK
- **Recall**: De todos los RISK reales, cuÃ¡ntos detectamos
- **F1-Score**: Balance entre precision y recall
- **AUC**: Ãrea bajo la curva ROC

## ğŸ‘¥ Contribuciones

Este proyecto es parte de un trabajo de investigaciÃ³n acadÃ©mica. Para sugerencias o mejoras, contacta al autor.


**Â¡Gracias por usar HeClaMoSTC!**âœ¨
